{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!pip install --user git+https://github.com/bolein/keras_img_iterator.git --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!pip install h5py --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now restart your kernel with Kernel -> Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# !!! DO NOT READOWNLOAD EVERY TIME !!!\n",
    "# Download the data (need only once!!)\n",
    "\n",
    "## Load Libraries\n",
    "import os\n",
    "import requests, zipfile, io\n",
    "\n",
    "# load data into platform\n",
    "url = requests.get('https://he-s3.s3.amazonaws.com/media/hackathon/deep-learning-challenge-1/identify-the-objects/a0409a00-8-dataset_dp.zip')\n",
    "data = zipfile.ZipFile(io.BytesIO(url.content))\n",
    "data.extractall('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check if the files have been download in current directory\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import save_model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_img_iterator import SingleDirectoryIterator\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "def convnet(num_classes, image_size):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(image_size, image_size, 3),\n",
    "                     activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D vectors\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('data/train.csv', header=0) \n",
    "filenames = meta_data['image_id'].apply(lambda id: id + '.png').values\n",
    "labels = meta_data['label'].values\n",
    "classes = list(set(labels))\n",
    "\n",
    "# split into test and validation\n",
    "files_train, files_validate, labels_train, labels_validate = \\\n",
    "    train_test_split(filenames, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "num_train_samples = files_train.shape[0]\n",
    "num_val_samples = files_validate.shape[0]\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2572 files belonging to 25 classes.\n",
      "Found 643 files belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "batch_size = 32\n",
    "image_size = 128\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2)\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "# only rescaling\n",
    "test_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_iterator = SingleDirectoryIterator(\n",
    "    directory='data/train_img/',\n",
    "    filenames=files_train,\n",
    "    labels=labels_train,\n",
    "    classes=classes,\n",
    "    image_data_generator=train_gen,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    seed=1337)\n",
    "\n",
    "validation_iterator = SingleDirectoryIterator(\n",
    "    directory='data/train_img/',\n",
    "    filenames=files_validate,\n",
    "    labels=labels_validate,\n",
    "    classes=classes,\n",
    "    image_data_generator=test_gen,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    seed=1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialize and compile the model\n",
    "model = convnet(num_classes, image_size)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# OR load from saved file (only if the model previously saved)\n",
    "model = load_model('model_0.321674930874.h5', compile = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "215/215 [==============================] - 77s - loss: 2.1813 - acc: 0.3403 - val_loss: 2.1692 - val_acc: 0.3375\n",
      "Epoch 2/40\n",
      "215/215 [==============================] - 59s - loss: 2.1424 - acc: 0.3554 - val_loss: 2.1596 - val_acc: 0.3499\n",
      "Epoch 3/40\n",
      "215/215 [==============================] - 68s - loss: 2.1263 - acc: 0.3605 - val_loss: 2.1517 - val_acc: 0.3655\n",
      "Epoch 4/40\n",
      "215/215 [==============================] - 55s - loss: 2.1323 - acc: 0.3574 - val_loss: 2.1798 - val_acc: 0.3313\n",
      "Epoch 5/40\n",
      "215/215 [==============================] - 54s - loss: 2.0951 - acc: 0.3628 - val_loss: 2.3372 - val_acc: 0.3204\n",
      "Epoch 6/40\n",
      "215/215 [==============================] - 53s - loss: 2.0891 - acc: 0.3791 - val_loss: 2.0628 - val_acc: 0.3733\n",
      "Epoch 7/40\n",
      "215/215 [==============================] - 55s - loss: 2.0530 - acc: 0.3779 - val_loss: 2.1221 - val_acc: 0.3717\n",
      "Epoch 8/40\n",
      "215/215 [==============================] - 55s - loss: 2.0005 - acc: 0.3930 - val_loss: 2.0440 - val_acc: 0.3701\n",
      "Epoch 9/40\n",
      "215/215 [==============================] - 83s - loss: 2.0120 - acc: 0.3857 - val_loss: 2.0310 - val_acc: 0.3872\n",
      "Epoch 10/40\n",
      "215/215 [==============================] - 78s - loss: 1.9981 - acc: 0.3833 - val_loss: 2.0600 - val_acc: 0.3919\n",
      "Epoch 11/40\n",
      "215/215 [==============================] - 59s - loss: 1.9656 - acc: 0.3954 - val_loss: 2.0005 - val_acc: 0.4152\n",
      "Epoch 12/40\n",
      "215/215 [==============================] - 56s - loss: 1.9914 - acc: 0.3822 - val_loss: 2.0762 - val_acc: 0.3624\n",
      "Epoch 13/40\n",
      "215/215 [==============================] - 54s - loss: 1.9952 - acc: 0.3957 - val_loss: 2.0608 - val_acc: 0.3546\n",
      "Epoch 14/40\n",
      "215/215 [==============================] - 62s - loss: 1.9363 - acc: 0.4178 - val_loss: 2.0352 - val_acc: 0.4152\n",
      "Epoch 15/40\n",
      "215/215 [==============================] - 55s - loss: 1.9179 - acc: 0.4291 - val_loss: 2.0475 - val_acc: 0.4059\n",
      "Epoch 16/40\n",
      "215/215 [==============================] - 80s - loss: 1.9220 - acc: 0.4202 - val_loss: 1.9885 - val_acc: 0.4184\n",
      "Epoch 17/40\n",
      "215/215 [==============================] - 56s - loss: 1.9160 - acc: 0.4015 - val_loss: 1.9721 - val_acc: 0.4012\n",
      "Epoch 18/40\n",
      "215/215 [==============================] - 68s - loss: 1.8601 - acc: 0.4252 - val_loss: 2.0388 - val_acc: 0.3888\n",
      "Epoch 19/40\n",
      "215/215 [==============================] - 64s - loss: 1.8983 - acc: 0.4167 - val_loss: 2.1186 - val_acc: 0.3950\n",
      "Epoch 20/40\n",
      "215/215 [==============================] - 60s - loss: 1.8890 - acc: 0.4295 - val_loss: 2.0153 - val_acc: 0.3981\n",
      "Epoch 21/40\n",
      "215/215 [==============================] - 54s - loss: 1.8289 - acc: 0.4391 - val_loss: 1.9974 - val_acc: 0.4355\n",
      "Epoch 22/40\n",
      " 42/215 [====>.........................] - ETA: 39s - loss: 1.8442 - acc: 0.4722"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 40\n",
    "\n",
    "validation_iterator.reset()\n",
    "train_iterator.reset()\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_iterator,\n",
    "    steps_per_epoch=num_train_samples // batch_size + 1,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_iterator,\n",
    "    validation_steps=num_val_samples // batch_size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Visualize learning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model scored 0.321674930874 on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/fs01/user/s7f8-8b789a734450bf-e3f006c1cf76/.local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Calculate f1-score against validation set\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Set up iterator for test set\n",
    "metric_iterator = SingleDirectoryIterator(\n",
    "    directory='data/train_img/',\n",
    "    filenames=files_validate,\n",
    "    image_data_generator=test_gen,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    shuffle=False)\n",
    "\n",
    "predictions = model.predict_generator(\n",
    "    generator=metric_iterator,\n",
    "    steps=num_val_samples // batch_size + 1)\n",
    "\n",
    "# binarize validation labels\n",
    "encode = np.vectorize(lambda label: classes.index(label)) # encode to integers\n",
    "y_true = to_categorical(encode(labels_validate), num_classes) # encode to one-hot vectors\n",
    "\n",
    "int_labels = np.argmax(predictions, axis=1)\n",
    "y_predicted = to_categorical(int_labels, num_classes)\n",
    "\n",
    "score = f1_score(y_true, y_predicted, average='weighted')\n",
    "\n",
    "print(\"model scored {} on validation set\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# top 5 predictions\n",
    "from keras.preprocessing.image import load_img\n",
    "for i in range(5):\n",
    "    print('I see this product is ' + classes[int_labels[i]])\n",
    "    plt.imshow(load_img('data/train_img/' + files_validate[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "# Read test data set\n",
    "test_data = pd.read_csv('data/test.csv', header=0)\n",
    "files_test = test_data['image_id'].apply(lambda id: id + '.png').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set up iterator for test set\n",
    "test_iterator = SingleDirectoryIterator(\n",
    "    directory='data/test_img/',\n",
    "    filenames=files_test,\n",
    "    image_data_generator=test_gen,\n",
    "    batch_size=batch_size,\n",
    "    target_size=(image_size, image_size),\n",
    "    shuffle=False)\n",
    "\n",
    "# make prediction\n",
    "num_test_samples = files_test.shape[0]\n",
    "predictions = model.predict_generator(\n",
    "    generator=test_iterator,\n",
    "    steps=num_test_samples // batch_size + 1)\n",
    "\n",
    "test_labels = [classes[i] for i in np.argmax(predictions, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# function for downloading results\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "\n",
    "def create_download_link(df, filename):  \n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{filename}</a>'\n",
    "    html = html.format(payload=payload,filename=filename)\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save to file and create download link\n",
    "submission = pd.DataFrame({'image_id':test_data.image_id, 'label':test_labels})\n",
    "create_download_link(submission, \"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training complete. model was saved as ', 'model_0.321674930874.h5')\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model_file = 'model_{}.h5'.format(score)\n",
    "save_model(model, model_file)\n",
    "print('Training complete. model was saved as ', model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
